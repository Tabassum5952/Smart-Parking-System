{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smart_Parking.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNmYw5qH4mW8",
        "outputId": "460705bf-8d29-4ad7-ca1f-6079ead8fcdc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX6pgPLnwg7I"
      },
      "source": [
        "import  os\n",
        "os.chdir('/content/drive/MyDrive/Mask_RCNN-master/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmEySGZP0KB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3953850-856f-4fda-95fb-c50298d9fe71"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN052_sJ0RfF",
        "outputId": "a012c477-ff31-48ea-c7de-cc06be7698ad"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPuYIlZeTYpd",
        "outputId": "07d6d9e9-3ab7-43d7-ef39-1289e35414fa"
      },
      "source": [
        "pip install twilio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twilio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/51/aa4a4339bb4fcaa255c055911a60eeec6be867db30ef2bc3abac55174abe/twilio-6.59.0.tar.gz (480kB)\n",
            "\r\u001b[K     |▊                               | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 18.8MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 15.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 14.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 174kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 184kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 204kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 215kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 225kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 235kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 245kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 266kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 276kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 296kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 307kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 317kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 327kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 337kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 348kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 358kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 368kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 378kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 389kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 399kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 409kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 419kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 430kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 440kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 450kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 460kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 471kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from twilio) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from twilio) (2018.9)\n",
            "Collecting PyJWT==1.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from twilio) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (2.10)\n",
            "Building wheels for collected packages: twilio\n",
            "  Building wheel for twilio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twilio: filename=twilio-6.59.0-py2.py3-none-any.whl size=1268922 sha256=14d42cc63cac8757117b680390eb48b73ace30202534f6a1ff0de735bcaa3d7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/eb/43/33d7e4374b4d83eca3d7563fdf06ce55462f4c0b5adc84d2ef\n",
            "Successfully built twilio\n",
            "Installing collected packages: PyJWT, twilio\n",
            "Successfully installed PyJWT-1.7.1 twilio-6.59.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4pJdSyJE-Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54cfc8c-078a-4db0-e714-a422163f4b5a"
      },
      "source": [
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import matplotlib as pt\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import mrcnn.config\n",
        "import mrcnn.utils\n",
        "from mrcnn.model import MaskRCNN\n",
        "import imutils\n",
        "from pathlib import Path\n",
        "from twilio.rest import Client"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOv8ibh7RQM1"
      },
      "source": [
        "\n",
        "# Twilio config\n",
        "twilio_account_sid = ' '\n",
        "twilio_auth_token = ' '\n",
        "twilio_phone_number = ' '\n",
        "destination_phone_number = ' '\n",
        "client = Client(twilio_account_sid, twilio_auth_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "zfDnEnrRTwlq",
        "outputId": "d563cd07-5cda-485e-ef7c-1b2317bd6156"
      },
      "source": [
        "# Mask-RCNN config\n",
        "class MaskRCNNConfig(mrcnn.config.Config):\n",
        "    NAME = \"coco_pretrained_model_config\"\n",
        "    IMAGES_PER_GPU = 1\n",
        "    GPU_COUNT = 1\n",
        "    NUM_CLASSES = 1 + 80  \n",
        "    DETECTION_MIN_CONFIDENCE = 0.6 \n",
        "\n",
        "# Root dir\n",
        "ROOT_DIR = Path(\".\")\n",
        "\n",
        "#Trained model loc\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "#if not os.path.exists(COCO_MODEL_PATH):\n",
        " #   mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "\n",
        "\n",
        "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=MaskRCNNConfig())\n",
        "\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "VIDEO_SOURCE = \"./video.mp4\"\n",
        "video_capture = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "\n",
        "# spotted parking spaces\n",
        "parked_car_boxes = None\n",
        "\n",
        "\n",
        "\n",
        "free_space_frames = False\n",
        "sms_sent = False\n",
        "count = 0\n",
        "temp = np.array(4,)\n",
        "\n",
        "\n",
        "# Filter to only cars\n",
        "def get_car_boxes(boxes, class_ids):\n",
        "    car_boxes = []\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        if class_ids[i] in [3, 8, 6]:\n",
        "            car_boxes.append(box)\n",
        "\n",
        "    return np.array(car_boxes)\n",
        "\n",
        "#parked_car_boxes1 = [None] * 11\n",
        "\n",
        "\n",
        "while video_capture.isOpened():\n",
        "    success, frame = video_capture.read()\n",
        "    \n",
        "    #image = frame\n",
        "    if not success:\n",
        "        print(\"couldn't read video\")\n",
        "        break\n",
        "        \n",
        "    elif count<60:\n",
        "      #create another video reader object to compare the two frames and verify the possibility of motion\n",
        "      success, frame2 = video_capture.read()\n",
        "      d = cv2.absdiff(frame, frame2)  \n",
        "      grey = cv2.cvtColor(d, cv2.COLOR_BGR2GRAY)\n",
        "      blur = cv2.GaussianBlur(grey, (1, 1), 0)\n",
        "      ret, th = cv2.threshold( blur, 20, 255, cv2.THRESH_BINARY)\n",
        "      \n",
        "      #perform these morphological transformations to erode the car which is moving so that it is not detected by MASKRCNN. Take the eorsion levels to be high. \n",
        "      dilated = cv2.dilate(th, np.ones((10, 10), np.uint8), iterations=1 )\n",
        "      eroded = cv2.erode(dilated, np.ones((30, 30), np.uint8), iterations=1 )\n",
        "        \n",
        "      #fill the contours for even a better morphing of the vehicle\n",
        "      c, h = cv2.findContours(eroded, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      frame2 = cv2.drawContours(frame2, c, -1, (0,0,0), cv2.FILLED)\n",
        "      \n",
        " \n",
        "\n",
        "       \n",
        "      if count%5 == 0:\n",
        "        print(\"Current frame counter\" + str(count))\n",
        "        pt.pyplot.imshow(frame2)\n",
        "        pt.pyplot.show()\n",
        "        \n",
        "      count = count + 1\n",
        "      continue\n",
        "    \n",
        "    # Converting the image from BGR color used by OpenCV to RGB color. \n",
        "    rgb_image=frame[:, :,::-1]\n",
        "     \n",
        "    \n",
        "    if parked_car_boxes is None:\n",
        "        print(\"going in to mark vehicles. Frame number:  \", count)\n",
        "       \n",
        "        # This is the first frame of video - assume all the cars detected are in parking spaces.\n",
        "        results = model.detect([rgb_image], verbose=0)\n",
        "        r = results[0]\n",
        "        parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "          \n",
        "          \n",
        "    elif len(parked_car_boxes)!=0:\n",
        "        results = model.detect([rgb_image], verbose=0)\n",
        "        r = results[0]\n",
        "        # Get where cars are currently located in the frame\n",
        "        car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "\n",
        "        # See how much those cars overlap with the known parking spaces\n",
        "        overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes)\n",
        "\n",
        "    \n",
        "        # Loop through each known parking space box\n",
        "        for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
        "\n",
        "            # For this parking space, find the max amount it was covered by any\n",
        "            # car that was detected in our image (doesn't really matter which car)\n",
        "            max_IoU_overlap = np.max(overlap_areas)\n",
        "\n",
        "            # Get the top-left and bottom-right coordinates of the parking area\n",
        "            y1, x1, y2, x2 = parking_area\n",
        "\n",
        "            # Check if the parking space is occupied by seeing if any car overlaps\n",
        "            # it by more than 0.15 using IoU\n",
        "            if max_IoU_overlap < 0.15:\n",
        "                # Parking space not occupied! Draw a green box around it\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "                # Flag that we have seen at least one open space\n",
        "                free_space = True\n",
        "            else:\n",
        "                # Parking space is still occupied - draw a red box around it\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
        "\n",
        "            # Write the IoU measurement inside the box\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, f\"{max_IoU_overlap:0.2}\", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255))\n",
        "\n",
        "        # If at least one space was free, start counting frames\n",
        "        # This is so we don't alert based on one frame of a spot being open.\n",
        "        # This helps prevent the script triggered on one bad detection.\n",
        "    \n",
        "        if free_space:\n",
        "            free_space_frames += 1\n",
        "        else:\n",
        "            # If no spots are free, reset the count\n",
        "            free_space_frames = 0\n",
        "\n",
        "        # If a space has been free for several frames, we are pretty sure it is really free!\n",
        "        if free_space_frames > 2:\n",
        "                     \n",
        "            # If we haven't sent an SMS yet, sent it!\n",
        "            if not sms_sent:\n",
        "                print(\"SENDING SMS!!!\")\n",
        "                message = client.messages.create(\n",
        "                    body=\"Parking space available!!!\",\n",
        "                    from_=twilio_phone_number,\n",
        "                    to=destination_phone_number,\n",
        "                )\n",
        "                sms_sent = True\n",
        "                print(\"Hope you got the message on your phone\")\n",
        "  \n",
        "        # Show the frame of video on the screen\n",
        "#         cv2.imshow('Video', frame)\n",
        "    #saving each frame\n",
        "    name = str(count) + \".jpg\"\n",
        "    name = os.path.join('/content/drive/MyDrive/Mask_RCNN-master/tabassum', name)\n",
        "    cv2.imwrite(name, frame)\n",
        "    count+=1\n",
        "    \n",
        "   \n",
        "\n",
        "video_capture.release()\n",
        "# cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN-master/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN-master/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN-master/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN-master/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN-master/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN-master/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-51edc9bdc490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMaskRCNNConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOCO_MODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mVIDEO_SOURCE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./video.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mvideo_capture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIDEO_SOURCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Mask_RCNN-master/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2130\u001b[0;31m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     \"\"\"\n\u001b[1;32m   1261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'keras_version'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m         \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
          ]
        }
      ]
    }
  ]
}